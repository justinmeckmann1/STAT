{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Multiple Linear Regression 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, based on the **gender** variable, we can create a new variable that takes the form\n",
    "\\begin{equation*}\n",
    "x_{i}\n",
    "=\n",
    "\\begin{cases}\n",
    "1&\\text{if $ i $th person is female}\\\\\n",
    "0&\\text{if $ i $th person is male}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "and use this variable as a predictor in the regression equation. This results in the model\n",
    "\\begin{equation}\\label{eq:regr_dummy_credit}\n",
    "y_{i}\n",
    "=\\beta_{0}+\\beta_{1}x_{i}+\\epsilon_{i}\n",
    "=\n",
    "\\begin{cases}\n",
    "\\beta_{0}+\\beta_{1}+\\epsilon_{i}&\\text{if $ i $th person is female}\\\\\n",
    "\\beta_{0}+\\epsilon_{1}&\\text{if $ i $th person is male}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Now, $ \\beta_{0} $ can be interpreted as the average credit card balance among males, $\\beta_{0} + \\beta_{1} $ as the average credit card balance among females, and $ \\beta_{1} $ as the average difference in credit card balance between females and males. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.002\n",
      "Method:                 Least Squares   F-statistic:                    0.1836\n",
      "Date:                Fri, 07 Mar 2025   Prob (F-statistic):              0.669\n",
      "Time:                        11:21:58   Log-Likelihood:                -3019.3\n",
      "No. Observations:                 400   AIC:                             6043.\n",
      "Df Residuals:                     398   BIC:                             6051.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        509.8031     33.128     15.389      0.000     444.675     574.931\n",
      "x1            19.7331     46.051      0.429      0.669     -70.801     110.267\n",
      "==============================================================================\n",
      "Omnibus:                       28.438   Durbin-Watson:                   1.940\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.346\n",
      "Skew:                           0.583   Prob(JB):                     1.15e-06\n",
      "Kurtosis:                       2.471   Cond. No.                         2.66\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./data/Credit.csv')\n",
    "\n",
    "balance = df['Balance']\n",
    "\n",
    "# Initiate dummy variable with zeros:\n",
    "gender = np.zeros(len(balance))\n",
    "# Make 1 for Female:\n",
    "indices_Fem = df[df['Gender']=='Female'].index.values\n",
    "gender[indices_Fem] = 1\n",
    "\n",
    "# Fit model\n",
    "gender_sm = sm.add_constant(gender)\n",
    "model = sm.OLS(balance, gender_sm).fit()\n",
    "\n",
    "# Print summary:\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **.summary()** method of a fitted model shows the encoding of the *dummy variable* associated with **gender**. The average credit card debt for males is estimated to be $509.80$, whereas females are estimated to carry 19.73 in additional debt for a total of  $ \\;509.80+ \\; 19.73 = \\;529.53 $. \n",
    "\n",
    "However, we notice that the p-value for the dummy variable $ \\beta_{1} $ is $ 0.6690 $, hence it is very high. This indicates that there is no statistical evidence of a difference in average credit card balance between the genders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Multiple Linear Regression 4.6\n",
    "If we had coded males as 1 and females as 0, then the estimates for $ \\beta_{0} $ and $ \\beta_{1} $ would have been 529.53 and -19.73 respectively, leading once again to a prediction of credit card debt of $\\;529.73- \\;19.73= \\; 509.80 $ for males and a prediction of 529.53 for females. This is the same result we obtained with the **default** coding scheme.\n",
    "\n",
    "If we wish to change the coding scheme for the dummy variable, we can change it in **Python** by changing the coding scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                      -0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Fri, 07 Mar 2025   Prob (F-statistic):                nan\n",
      "Time:                        11:21:58   Log-Likelihood:                -3019.4\n",
      "No. Observations:                 400   AIC:                             6041.\n",
      "Df Residuals:                     399   BIC:                             6045.\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        520.0150     22.988     22.621      0.000     474.822     565.208\n",
      "x1                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                       28.709   Durbin-Watson:                   1.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.405\n",
      "Skew:                           0.582   Prob(JB):                     1.12e-06\n",
      "Kurtosis:                       2.464   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\envs\\FS25_STAT\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1860: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "# Following Example 4.5\n",
    "# Initiate dummy variable with zeros:\n",
    "gender = np.zeros(len(balance))\n",
    "# Make 1 for Male:\n",
    "indices_Mal = df[df['Gender'] == 'Male'].index.values\n",
    "gender[indices_Mal] = 1\n",
    "\n",
    "# Fit model\n",
    "gender_sm = sm.add_constant(gender)\n",
    "model = sm.OLS(balance, gender_sm).fit()\n",
    "\n",
    "# Print summary:\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Multiple Linear Regression 4.7\n",
    "Alternatively, instead of a $ 0/1 $ coding scheme, we could create a dummy variable \n",
    "\\begin{equation*}\n",
    "x_{i}\n",
    "=\n",
    "\\begin{cases}\n",
    "1&\\text{if $ i $th person is female}\\\\\n",
    "-1&\\text{if $ i $th person is male}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "and use this variable in the regression equation. This results in the model\n",
    "\\begin{equation*}\n",
    "y_{i}\n",
    "=\\beta_{0}+\\beta_{1}x_{i}+\\epsilon_{i}\n",
    "=\n",
    "\\begin{cases}\n",
    "\\beta_{0}+\\beta_{1}+\\epsilon_{i}&\\text{if $ i $th person is male}\\\\\n",
    "\\beta_{0}-\\beta_{1}+\\epsilon_{1}&\\text{if $ i $th person is female}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Now $ \\beta_{0} $ can be interpreted as the overall credit card balance (ignoring the gender effect), and $ \\beta_{1} $ is the amount that females are above the average and males are below the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                      -0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Fri, 07 Mar 2025   Prob (F-statistic):                nan\n",
      "Time:                        11:21:58   Log-Likelihood:                -3019.4\n",
      "No. Observations:                 400   AIC:                             6041.\n",
      "Df Residuals:                     399   BIC:                             6045.\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        520.0150     22.988     22.621      0.000     474.822     565.208\n",
      "==============================================================================\n",
      "Omnibus:                       28.709   Durbin-Watson:                   1.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.405\n",
      "Skew:                           0.582   Prob(JB):                     1.12e-06\n",
      "Kurtosis:                       2.464   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Following Example 4.6\n",
    "# Initiate dummy variable with ones:\n",
    "gender = np.ones(len(balance))\n",
    "# Make -1 for Male:\n",
    "indices_Mal = df[df['Gender'] == 'Male'].index.values\n",
    "gender[indices_Mal] = -1\n",
    "\n",
    "# Fit model\n",
    "gender_sm = sm.add_constant(gender)\n",
    "model = sm.OLS(balance, gender_sm).fit()\n",
    "\n",
    "# Print summary:\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the estimate for $ \\beta_{0} $ \n",
    "would be 519.67 , halfway between the male and female averages of 509.80 and 529.53. The estimate for $ \\beta_{1} $ would be 9.87, which is half of 19.73, the average difference between females and males. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Multiple Linear Regression 4.8\n",
    "For example, for the **ethnicity** variable which has *three* levels we create *two* dummy variables. The first could be\n",
    "\\begin{equation*}\n",
    "x_{i1}\n",
    "=\n",
    "\\begin{cases}\n",
    "1&\\text{if $ i $th person is Asian}\\\\\n",
    "0&\\text{if $ i $th person is not Asian}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "and the second could be\n",
    "\\begin{equation*}\n",
    "x_{i2}\n",
    "=\n",
    "\\begin{cases}\n",
    "1&\\text{if $ i $th person is Caucasian}\\\\\n",
    "0&\\text{if $ i $th person is not Caucasian}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "Then both of these variables can be used in the regression equation, in \n",
    "order to obtain the model\n",
    "\\begin{equation}\\label{eq:two_dummy_variables}\n",
    "y_{i}\n",
    "=\\beta_{0}+\\beta_{1}x_{i1}+\\beta_{2}x_{i2}+\\epsilon_{i}\n",
    "=\n",
    "\\begin{cases}\n",
    "\\beta_{0}+\\beta_{1}+\\epsilon_{i}&\\text{if $ i $th person is Asian}\\\\\n",
    "\\beta_{0}+\\beta_{2}+\\epsilon_{i}&\\text{if $ i $th person is Caucasian}\\\\\n",
    "\\beta_{0}+\\epsilon_{i}&\\text{if $ i $th person is Afro-American}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Now $ \\beta_{0} $ can be interpreted as the average credit card balance for African Americans, $ \\beta_{1} $ can be interpreted as the difference in the average balance between the Asian and African American categories, and $ \\beta_{2} $ can be interpreted as the difference in the average balance between the Caucasian and African American categories. \n",
    "\n",
    "- There will always be one fewer dummy variable than the number of levels.\n",
    "- The level with no dummy variable African American in the example - is known as the *baseline*.\n",
    "- The equation \n",
    "    \\begin{equation*}\n",
    "    y_{i}\n",
    "    =\\beta_{0}+\\beta_{1}+\\beta_{2}+\\epsilon_{i}\n",
    "    \\end{equation*}\n",
    "\n",
    "    does not make sense, since this person would be Asian *and* Caucasian.\n",
    "\n",
    "From the summary below, we see that the estimated **balance** for the baseline, African American, is   531.00. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.005\n",
      "Method:                 Least Squares   F-statistic:                   0.04344\n",
      "Date:                Fri, 07 Mar 2025   Prob (F-statistic):              0.957\n",
      "Time:                        11:21:58   Log-Likelihood:                -3019.3\n",
      "No. Observations:                 400   AIC:                             6045.\n",
      "Df Residuals:                     397   BIC:                             6057.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        531.0000     46.319     11.464      0.000     439.939     622.061\n",
      "x1           -18.6863     65.021     -0.287      0.774    -146.515     109.142\n",
      "x2           -12.5025     56.681     -0.221      0.826    -123.935      98.930\n",
      "==============================================================================\n",
      "Omnibus:                       28.829   Durbin-Watson:                   1.946\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.395\n",
      "Skew:                           0.581   Prob(JB):                     1.13e-06\n",
      "Kurtosis:                       2.460   Cond. No.                         4.39\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# dummy variabeln x1, x2 gemäss unserer Konvention\n",
    "\n",
    "# Following Example 4.7\n",
    "# Initiate dummy variable with zeros:\n",
    "ethnicity = np.zeros((len(balance),2))\n",
    "# Find indices \n",
    "indices_Asi = df[df['Ethnicity'] == 'Asian'].index.values\n",
    "indices_Cau = df[df['Ethnicity'] == 'Caucasian'].index.values\n",
    "# Set values\n",
    "ethnicity[indices_Asi, 0] = 1\n",
    "ethnicity[indices_Cau, 1] = 1\n",
    "\n",
    "# Fit model\n",
    "ethnicity_sm = sm.add_constant(ethnicity)\n",
    "model = sm.OLS(balance, ethnicity_sm).fit()\n",
    "\n",
    "# Print summary:\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is estimated that the Asian category will have $ 18.69 $ less debt than the African American category, and that the Caucasian category will have 12.50 less debt than the African American category. However, the p-values associated with the coefficient estimates for the two dummy variables are very large, suggesting no statistical evidence of a real difference in credit card balance between the ethnicities. Once again, the level selected as the baseline category is arbitrary, and the final predictions for each group will be the same regardless of this choice. However, the coefficients and their p-values do depend on the choice of dummy variable coding. Rather than rely on the individual coefficients, we can use an F-test to test \n",
    "\\begin{equation*}\n",
    "H_{0}:\\quad\n",
    "\\beta_{1}\n",
    "=\\beta_{2}\n",
    "=0\n",
    "\\end{equation*}\n",
    "\n",
    "The p-value does not depend on the coding. This F-test has a p-value of 0.96, indicating that we cannot reject the null hypothesis that there is *no* relationship between **balance** and **ethnicity**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0      False\n",
       " 1       True\n",
       " 2       True\n",
       " 3       True\n",
       " 4      False\n",
       "        ...  \n",
       " 395    False\n",
       " 396    False\n",
       " 397    False\n",
       " 398    False\n",
       " 399     True\n",
       " Name: Ethnicity, Length: 400, dtype: bool]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity = np.zeros((len(balance),2))\n",
    "[df['Ethnicity'] == 'Asian' ] # True if Asian, False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>71.408</td>\n",
       "      <td>7114</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>80.616</td>\n",
       "      <td>5308</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>26.400</td>\n",
       "      <td>5640</td>\n",
       "      <td>398</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>388</td>\n",
       "      <td>16.529</td>\n",
       "      <td>1357</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>391</td>\n",
       "      <td>135.118</td>\n",
       "      <td>10578</td>\n",
       "      <td>747</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>393</td>\n",
       "      <td>25.974</td>\n",
       "      <td>2308</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>18.701</td>\n",
       "      <td>5524</td>\n",
       "      <td>415</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender  \\\n",
       "1             2  106.025   6645     483      3   82         15  Female   \n",
       "2             3  104.593   7075     514      4   71         11    Male   \n",
       "3             4  148.924   9504     681      3   36         11  Female   \n",
       "7             8   71.408   7114     512      2   87          9    Male   \n",
       "12           13   80.616   5308     394      1   57          7  Female   \n",
       "..          ...      ...    ...     ...    ...  ...        ...     ...   \n",
       "385         386   26.400   5640     398      3   58         15  Female   \n",
       "387         388   16.529   1357     126      3   62          9    Male   \n",
       "390         391  135.118  10578     747      3   81         15  Female   \n",
       "392         393   25.974   2308     196      2   24         10    Male   \n",
       "399         400   18.701   5524     415      5   64          7  Female   \n",
       "\n",
       "    Student Married Ethnicity  Balance  \n",
       "1       Yes     Yes     Asian      903  \n",
       "2        No      No     Asian      580  \n",
       "3        No      No     Asian      964  \n",
       "7        No      No     Asian      872  \n",
       "12       No     Yes     Asian      204  \n",
       "..      ...     ...       ...      ...  \n",
       "385      No      No     Asian      905  \n",
       "387      No      No     Asian        0  \n",
       "390      No     Yes     Asian     1393  \n",
       "392      No      No     Asian        0  \n",
       "399      No      No     Asian      966  \n",
       "\n",
       "[102 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Ethnicity'] == 'Asian' ] # alle Asiaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   7,  12,  17,  18,  19,  20,  31,  34,  42,  43,\n",
       "        46,  48,  53,  54,  55,  56,  60,  66,  71,  72,  77,  79,  85,\n",
       "        87,  96, 106, 107, 109, 110, 113, 117, 120, 126, 131, 137, 142,\n",
       "       145, 149, 155, 158, 159, 164, 168, 170, 172, 177, 180, 183, 187,\n",
       "       191, 192, 199, 216, 218, 220, 223, 225, 229, 232, 236, 237, 239,\n",
       "       240, 242, 246, 250, 256, 257, 260, 261, 267, 272, 273, 285, 288,\n",
       "       290, 294, 297, 304, 305, 307, 308, 313, 316, 324, 327, 330, 344,\n",
       "       346, 349, 354, 357, 361, 364, 385, 387, 390, 392, 399], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_Cau = df[df['Ethnicity'] == 'Caucasian' ].index.values # Zeilennummer der Kaukasiern\n",
    "indices_Asi = df[df['Ethnicity'] == 'Asian' ].index.values # Zeilennummer der Asiaten\n",
    "indices_Asi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity[indices_Asi, 0] = 1 # Asiaten bekommen 1 in der ersten Spalte  --> x1\n",
    "ethnicity[indices_Cau, 1] = 1 # Kaukasier bekommen 1 in der zweiten Spalte --> x2\n",
    "ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Balance   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.005\n",
      "Method:                 Least Squares   F-statistic:                   0.04344\n",
      "Date:                Fri, 07 Mar 2025   Prob (F-statistic):              0.957\n",
      "Time:                        11:23:30   Log-Likelihood:                -3019.3\n",
      "No. Observations:                 400   AIC:                             6045.\n",
      "Df Residuals:                     397   BIC:                             6057.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        531.0000     46.319     11.464      0.000     439.939     622.061\n",
      "x1           -18.6863     65.021     -0.287      0.774    -146.515     109.142\n",
      "x2           -12.5025     56.681     -0.221      0.826    -123.935      98.930\n",
      "==============================================================================\n",
      "Omnibus:                       28.829   Durbin-Watson:                   1.946\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.395\n",
      "Skew:                           0.581   Prob(JB):                     1.13e-06\n",
      "Kurtosis:                       2.460   Cond. No.                         4.39\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "ethnicity_sm = sm.add_constant(ethnicity)\n",
    "model = sm.OLS(balance, ethnicity_sm).fit()\n",
    "\n",
    "# Print summary:\n",
    "print(model.summary())\n",
    "\n",
    "# Interpretation: \n",
    "# x1 --> 531 - 18.7 = 512.3\n",
    "# x2 --> 531 - 12.5 = 518.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FS25_STAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
