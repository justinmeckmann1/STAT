{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02861b71",
   "metadata": {},
   "source": [
    "# 2 - Logistic Regression & Support Vector Classifiers / Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy \n",
    "df , y, x, x_sm = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea86c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b400e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "import statsmodels.api as sm\n",
    "model = sm.GLM(y, x_sm, family=sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "prob_stud = model.predict([1, 1])       # where the first 1 indicates default and the second 1 indicates student\n",
    "prob_nonstud = model.predict([1, 0])    # where the first 1 indicates default and the second 0 indicates non-student\n",
    "\n",
    "print(f'Probability of default for student: {prob_stud[0]:.3f}')\n",
    "print(f'Probability of default for non-student: {prob_nonstud[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452691c",
   "metadata": {},
   "source": [
    "## Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02823ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# data\n",
    "x1 = [3, 2, 4, 1, 2, 4, 4]\n",
    "x2 = [4, 2, 4, 4, 1, 3, 1]\n",
    "y = ['red', 'red', 'red', 'red', 'blue', 'blue', 'blue']\n",
    "\n",
    "x = np.concatenate(([x1], [x2]), axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "cost = 10\n",
    "clf = svm.SVC(kernel='linear', C=cost)\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103bd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error rate\n",
    "n = x.shape[0] # dataset size\n",
    "y_pred = clf.predict(x)\n",
    "error = n - (y_pred == y).sum()\n",
    "error = error / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ac567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print attributes\n",
    "print(f'Number of support vectors: {len(clf.support_vectors_)}')\n",
    "print(f'Number of support vectors: {clf.n_support_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the hyperplane\n",
    "beta1, beta2 = clf.coef_[0][0], clf.coef_[0][1]\n",
    "beta0 = clf.intercept_[0]\n",
    "\n",
    "x1_hyperplane = np.linspace(1, 4, 2)\n",
    "x2_hyperplane = - beta1 / beta2 * x1_hyperplane - beta0 / beta2\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(x1_hyperplane, x2_hyperplane, '-k')\n",
    "\n",
    "ax.scatter(x1, x2, c=y)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "\n",
    "plt.title(\"Maximal margin Hyperplane\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcafcf9d",
   "metadata": {},
   "source": [
    "#### Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "# Set parameters to be tuned. Other options can be added\n",
    "\n",
    "costs = np.linspace(1, 50, 20)\n",
    "tune_parameters = {'C': costs}\n",
    "n_folds = 10\n",
    "\n",
    "# Tune SVM\n",
    "clf_tune = GridSearchCV(svm.SVC(kernel='linear'), \n",
    "                        tune_parameters,\n",
    "                        cv=n_folds)\n",
    "\n",
    "clf_tune.fit(x, y)\n",
    "\n",
    "# Save Tune scores:\n",
    "error_tune = 1 - clf_tune.cv_results_['mean_test_score']\n",
    "error_std = clf_tune.cv_results_['std_test_score'] / np.sqrt(n_folds) \n",
    "\n",
    "best_cost = clf_tune.best_params_['C']\n",
    "print(f\"Best cost: {best_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9609d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally plot the cross-validation error\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(costs, error_tune,\n",
    "'-k', alpha=0.8, label='Cross validation error')\n",
    "ax.plot(costs, error_tune + error_std, '--b',\n",
    "        costs, error_tune - error_std, '--b',\n",
    "        alpha=0.8, label='Cross validation error standard deviation')\n",
    "\n",
    "ax.set_xlabel('cost')\n",
    "ax.set_ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70791b",
   "metadata": {},
   "source": [
    "## Support Vector Machines: Polynomial Kernel\n",
    "kernel='poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.linspace(0.5, 100, 5)\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "tune_parameters = {'C': costs,\n",
    "                   'degree': degree}\n",
    "n_folds = 10\n",
    "\n",
    "# Tune SVM\n",
    "clf_tune = GridSearchCV(svm.SVC(kernel='poly'), \n",
    "                        tune_parameters,\n",
    "                        cv=n_folds)\n",
    "\n",
    "clf_tune.fit(x, y)\n",
    "\n",
    "# Save Tune scores:\n",
    "error_tune = 1 - clf_tune.cv_results_['mean_test_score']\n",
    "error_tune = error_tune.reshape(len(costs), len(degree))\n",
    "\n",
    "best_cost = clf_tune.best_params_['C']\n",
    "best_degree = clf_tune.best_params_['degree']\n",
    "\n",
    "print(f\"Best parameter Polynomial: {clf_tune.best_params_},\")\n",
    "print(f\"Best score Polynomial: {np.round(1 - clf_tune.best_score_, 4):.4f}\")\n",
    "\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Plot error vs degree for each value for cost:\n",
    "for i in range(len(costs)):\n",
    "        line, = ax.plot(degree, error_tune[i, :],'.-', alpha=0.8)\n",
    "        line.set_label(('cost=' + str(costs[i])))\n",
    "\n",
    "ax.set_xlabel('degree')\n",
    "ax.set_ylabel('CV error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64f863",
   "metadata": {},
   "source": [
    "## Support Vector Machines: Radial Kernel\n",
    "kernel='rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.linspace(0.5, 10, 5)\n",
    "gamma = np.linspace(0.0005, 0.005, 5)\n",
    "\n",
    "tune_parameters = {'C': costs,\n",
    "                   'gamma': gamma}\n",
    "n_folds = 10\n",
    "\n",
    "# Tune SVM\n",
    "clf_tune = GridSearchCV(svm.SVC(kernel='rbf'), \n",
    "                        tune_parameters,\n",
    "                        cv=n_folds)\n",
    "\n",
    "clf_tune.fit(x, y)\n",
    "\n",
    "# Save Tune scores:\n",
    "error_tune = 1 - clf_tune.cv_results_['mean_test_score']\n",
    "error_tune = error_tune.reshape(len(costs), len(gamma))\n",
    "\n",
    "best_cost = clf_tune.best_params_['C']\n",
    "best_gamma = clf_tune.best_params_['gamma']\n",
    "\n",
    "print(f\"Best parameter Radial: {clf_tune.best_params_}\")\n",
    "print(f\"Best score Radial: {np.round(1 - clf_tune.best_score_, 4):.4f}\")\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Plot error vs gamma for each value for cost:\n",
    "for i in range(len(costs)):\n",
    "        line, = ax.plot(gamma, error_tune[i, :],'.-', alpha=0.8)\n",
    "        line.set_label(('cost=' + str(costs[i])))\n",
    "\n",
    "ax.set_xlabel('gamma')\n",
    "ax.set_ylabel('CV error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e357a0",
   "metadata": {},
   "source": [
    "## Metrics / Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17512d40",
   "metadata": {},
   "source": [
    "#### Test / Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(['mpg01'], axis=1)\n",
    "y = df['mpg01']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2) \n",
    "i = df.index\n",
    "# Index of train\n",
    "i_train = np.random.choice(i, replace=False,\n",
    "                           size=800)\n",
    "\n",
    "# Save DataFrames\n",
    "df_train = df.iloc[i_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1704ab9",
   "metadata": {},
   "source": [
    "#### Classification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Train\n",
    "x_train_sm = sm.add_constant(x_train)\n",
    "model = sm.GLM(y_train, x_train_sm, family=sm.families.Binomial()).fit()\n",
    "\n",
    "\n",
    "# Test\n",
    "def class_err(x, y, model):\n",
    "    \"\"\" Find classification error for given\n",
    "    x, y and fitted model \"\"\"\n",
    "    y_pred = model.predict(x)\n",
    "    # Round to 0 or 1\n",
    "    y_pred = y_pred.round()\n",
    "    # Classification error\n",
    "    e = abs(y - y_pred).mean()\n",
    "    return e\n",
    "\n",
    "\n",
    "x_test_sm = sm.add_constant(x_test)\n",
    "\n",
    "e_train = class_err(x_train_sm, y_train, model)\n",
    "e_test = class_err(x_test_sm, y_test, model)\n",
    "\n",
    "print('Train error:\\n', np.round(e_train, 4),\n",
    "'\\nTest error:\\n', np.round(e_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8389801",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64afb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_pred_test = model.predict(x_test_sm).round()\n",
    "confusion_test = pd.DataFrame({'predicted': y_pred_test,'true': y_test})\n",
    "confusion_test = pd.crosstab(confusion_test.predicted,confusion_test.true,\n",
    "                             margins=True, margins_name=\"Sum\")\n",
    "\n",
    "print(\"\\nConfusion Matrix - Test Set:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e435ef",
   "metadata": {},
   "source": [
    "#### TP, FP, FN, TN and Accuracy, Precision, Recall, F-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ea0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hinweis: zuerst confusion berechnen \n",
    "tp = confusion_test[1][1]\n",
    "tn = confusion_test[0][0]\n",
    "fp = confusion_test[1][0]\n",
    "fn = confusion_test[0][1]\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\"\n",
    "      f\"\\nPrecision: {precision:.4f}\"\n",
    "      f\"\\nRecall: {recall:.4f}\"\n",
    "      f\"\\nF1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdda8fc",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c3f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FS25_STAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
