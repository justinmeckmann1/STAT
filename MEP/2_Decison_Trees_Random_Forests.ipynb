{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944eb3a2",
   "metadata": {},
   "source": [
    "# 2 - Decison Trees & Random_Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = None, None\n",
    "x_test, y_test = None, None\n",
    "x_train, y_train = None, None\n",
    "X_train, X_test = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e8888",
   "metadata": {},
   "source": [
    "## Fit Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set random seed for test-train split:\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# tree settings:\n",
    "tree_settings = {'criterion': 'entropy',\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 5,\n",
    "    'min_impurity_decrease': 0.005 ,\n",
    "    'random_state': 1,\n",
    "    'max_leaf_nodes': 10} # use after pruning \n",
    "\n",
    "# Create and fit Decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier().set_params(**tree_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae870d",
   "metadata": {},
   "source": [
    "## Fit Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfc_settings = {'oob_score': True,  # berechnet den OOB-Score\n",
    "    'max_features': n_features,     # Anzahl predictors pro, i.d.r n_features = round(np.sqrt(X_train.shape[1]))\n",
    "    'random_state': 1,              \n",
    "    'warm_start': True,\n",
    "    'n_estimators': 100,            # Anzahl der Bäume\n",
    "    }\n",
    "\n",
    "rfr = RandomForestRegressor(**rfc_settings)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Parameters:\\n\", rfr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6805385",
   "metadata": {},
   "source": [
    "## Fit Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6062c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_settings = {'oob_score': True,  # berechnet den OOB-Score\n",
    "    'max_features': n_features,     # Anzahl predictors pro, i.d.r n_features = round(np.sqrt(X_train.shape[1]))\n",
    "    'random_state': 1,              \n",
    "    'warm_start': True,\n",
    "    'n_estimators': 100,            # Anzahl der Bäume\n",
    "    }\n",
    "\n",
    "rfr = RandomForestClassifier(**rfc_settings)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Parameters:\\n\", rfr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27447fa4",
   "metadata": {},
   "source": [
    "#### Classification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = 1 - (y_test == y_test_pred).mean()\n",
    "err_train = 1 - (y_train == y_train_pred).mean()\n",
    "\n",
    "print('Test error:', np.round(err_test, 3))\n",
    "print('Train error:', np.round(err_train, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba1f16",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e153a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred = rfr.predict(X_test)\n",
    "MSE = mean_squared_error(y_test, pred) \n",
    "# or \n",
    "MSE = np.mean((y_test - y_test_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfe1a9",
   "metadata": {},
   "source": [
    "### Resid Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d792126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict\n",
    "pred = rfr.predict(X_test)\n",
    "error = y_test - pred\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(x=y_test, y=error)\n",
    "plt.xlabel('predicted medv')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d27db",
   "metadata": {},
   "source": [
    "### Find Optimal # of feature for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ab89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_features = np.arange(1, X_train.shape[1] + 1, 1) # number of features to consider at each split\n",
    "MSE = []\n",
    "\n",
    "for n in n_features:\n",
    "    rfr = RandomForestRegressor(max_features=n)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    MSE.append( mean_squared_error(y_test, rfr.predict(X_test)))\n",
    "\n",
    "plt.plot(n_features, MSE, marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1a408",
   "metadata": {},
   "source": [
    "## Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FI = pd.DataFrame(data={'Feature': x_train.columns.values,\n",
    "                        'Importance': clf.feature_importances_})\n",
    "\n",
    "print('Feature importances:\\n', FI,\n",
    "'\\n\\nTree depth:\\n', clf.get_depth(),\n",
    "'\\nNumber of leaves:\\n', clf.get_n_leaves(),\n",
    "'\\nTraining error:\\n',\n",
    "np.round(1 - clf.score(x_train, y_train), 3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04689d",
   "metadata": {},
   "source": [
    "#### Plot Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbeecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plots\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "# Plot Decision Tree\n",
    "tree.plot_tree(clf, ax=ax, fontsize=8, impurity=False, label='Root',\n",
    "feature_names=x.columns.values,\n",
    "class_names=['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91acf64",
   "metadata": {},
   "source": [
    "#### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76aeca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d7ba513",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "# Create confusion matrix\n",
    "def confusion(y_true, y_pred):\n",
    "    conf = pd.DataFrame({'predicted': y_pred, 'true': y_true})\n",
    "    conf = pd.crosstab(conf.predicted, conf.true,\n",
    "                       margins=True, margins_name=\"Sum\")\n",
    "    return conf\n",
    "\n",
    "print('Test data:\\n',\n",
    "      confusion(y_test.T.to_numpy(), y_test_pred))\n",
    "print('\\n\\nTrain data:\\n',\n",
    "      confusion(y_train.T.to_numpy(), y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da065773",
   "metadata": {},
   "source": [
    "#### n-Fold Cross Validation\n",
    "mit cost complexity pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23916276",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_f = 5 # number of folds\n",
    "# Train:\n",
    "node = []\n",
    "score_train, score_test = [], []\n",
    "i = x_train.index\n",
    "# Crossval size:\n",
    "cv_size = int(len(i) / n_f)\n",
    "\n",
    "for fold in range(n_f):\n",
    "    \"\"\" 1. Split train data in train/crossval fold \"\"\"\n",
    "    # Index of cross-valdation fold\n",
    "    i_cv_fold = i[np.arange(fold*cv_size, \n",
    "                            (fold + 1)*cv_size,1)]\n",
    "    # Save DataFrames\n",
    "    X_train_fold = x_train.drop(i_cv_fold)\n",
    "    X_cv_fold = x_train.loc[i_cv_fold]\n",
    "    y_train_fold = y_train.drop(i_cv_fold)\n",
    "    y_cv_fold = y_train.loc[i_cv_fold]\n",
    "    \n",
    "    \"\"\" 2. Find score and size of respective Trees T(alpha) \"\"\"\n",
    "    path = clf.cost_complexity_pruning_path(X_train_fold,\n",
    "    y_train_fold)\n",
    "    for alpha in path.ccp_alphas:\n",
    "        # Create and fit Decision tree classifier\n",
    "        clf_cv = tree.DecisionTreeClassifier(ccp_alpha=alpha)\n",
    "        clf_cv.set_params(**tree_settings)\n",
    "        clf_cv = clf_cv.fit(X_train_fold, y_train_fold)\n",
    "        # Save node count:\n",
    "        node.append(clf_cv.get_n_leaves())\n",
    "        # Save Scores\n",
    "        score_train.append(clf_cv.score(X_train_fold, y_train_fold))\n",
    "        score_test.append(clf_cv.score(X_cv_fold, y_cv_fold))\n",
    "        \n",
    "\"\"\" 3. Average found scores per node \"\"\"\n",
    "node = pd.Series(node)\n",
    "node_sort = np.sort(node.unique())\n",
    "score_train = pd.Series(score_train)\n",
    "score_test = pd.Series(score_test)\n",
    "score_train_avg, score_test_avg, node_avg = [], [], []\n",
    "\n",
    "# Average per node\n",
    "for i in node_sort:\n",
    "    score_train_avg.append(score_train[node == i].mean())\n",
    "    score_test_avg.append(score_test[node == i].mean())\n",
    "\n",
    "# Optimal Treesize:\n",
    "opt_size = node_sort[np.argmax(score_test_avg)]\n",
    "print(opt_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce2bb9",
   "metadata": {},
   "source": [
    "#### Plot score vs. Size after n-Fold cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(node_sort, score_train_avg,\n",
    "'r-o', drawstyle=\"steps-post\", label='train')\n",
    "ax.plot(node_sort, score_test_avg,\n",
    "'g-o', drawstyle=\"steps-post\", label='CV')\n",
    "ax.set_xlabel(\"Size\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy vs Tree Size\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8ec9c",
   "metadata": {},
   "source": [
    "### Loop over n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "m = round(np.sqrt(X_train.shape[1]))\n",
    "\n",
    "rfc_settings = {'oob_score': True,\n",
    "    'max_features': m,     # Anzahl predictors pro \n",
    "    'random_state': 1,              \n",
    "    'warm_start': True,\n",
    "    'n_estimators': 100,            # Anzahl der Bäume\n",
    "    }\n",
    "\n",
    "rfr = RandomForestClassifier(**rfc_settings)\n",
    "\n",
    "# n_estimators to check: \n",
    "B = np.arange(15, 500, 2)\n",
    "MSE = []\n",
    "for b in B:\n",
    "    rfr.set_params(n_estimators=b)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    MSE.append(1 - rfr.oob_score_)\n",
    "\n",
    "plt.plot(B, MSE, marker='o')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB error')\n",
    "plt.title('OOB error vs. n_estimators')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FS25_STAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
